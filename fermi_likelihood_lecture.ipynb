{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic theory of likelihood \n",
    "===================\n",
    "\n",
    "This jupyter notebook gives a basic overview of the theory of likelihood and maximum likelihood estimators applied to *Fermi* LAT. \n",
    "\n",
    "In the introduction to some of the probabilistic concepts below, I was blatantly inspired by the excellent [Bayesian methods in astronomy](https://github.com/jakevdp/BayesianAstronomy) tutorial. In fact, I am copying parts of Jake Vanderplas' tutorial below. You should go and read it if you have the chance.\n",
    "\n",
    "Let's begin with some Python imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import seaborn # for plot formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamental questions of statistics\n",
    "\n",
    "There are two fundamental types of statistical questions we want to answer:\n",
    "\n",
    "**1. Model Fitting:** *Given this Model, what parameters best fit my data?*\n",
    "\n",
    "Examples:\n",
    "\n",
    "- What are the slope and intercept of a line of best-fit?\n",
    "- What is the frequency, amplitude, and phase of a sinusoidal fit?\n",
    "\n",
    "**2. Model Selection:** *Given two potential Models, which better describes my data?*\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Does a linear or quadratic fit describe our data better?\n",
    "\n",
    "Often one of the two models is a *null hypothesis*, or a baseline model in which the effect you're interested in is not observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will focus on frequentist *maximum likelihood* approaches as a way of performing both model fitting and model selection. Another approach is Bayesian methods, but given our time constraints we will not cover them.\n",
    "\n",
    "The starting point of maximum likelihood methods is to define the probability of seeing our data given the model—the likelihood:\n",
    "\n",
    "$$ P(data ~|~ scientific\\ model) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some symbols that will let us express this more easily:\n",
    "\n",
    "$$\n",
    "P(D ~|~ \\theta)\n",
    "$$\n",
    "\n",
    "- $\\theta$ represents the \"science\": the set of parameters that we are interested in constraining\n",
    "- $D$ represents the \"observed data\"\n",
    "\n",
    "It makes sense that the best-fit parameters that describe the data are those that maximize the likelihood defined above. Now all we need to do--as far as likelihood methods are concerned--is to compute the likelihood and maximize it. This should give us a point estimate of the model parameters that best describe the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple example of statistical model\n",
    "\n",
    "Since we want to maximize the likelihood, we need an expression to compute $P(D ~|~ \\theta)$ for our data as a function of the parameters $\\theta$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were given:\n",
    "\n",
    "- Data points $x_i, y_i$ with simple errorbars—this implies that probability for any *single* data point is a normal distribution about the true value\n",
    "- Model $y_M(x; \\theta)$ providing expected values\n",
    "\n",
    "then\n",
    "\n",
    "$$\n",
    "y_i \\sim \\mathcal{N}(y_M(x_i;\\theta), \\sigma)\n",
    "$$\n",
    "\n",
    "and the likelihood would be\n",
    "\n",
    "$$\n",
    "P(x_i,y_i\\mid\\theta) = \\frac{1}{\\sqrt{2\\pi\\varepsilon_i^2}} \\exp\\left(\\frac{-\\left[y_i - y_M(x_i;\\theta)\\right]^2}{2\\varepsilon_i^2}\\right)\n",
    "$$\n",
    "\n",
    "where $\\varepsilon_i$ are the (known) measurement errors indicated by the errorbars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming all the points are independent, we can find the *full likelihood by multiplying the individual likelihoods together*:\n",
    "\n",
    "$$\n",
    "P(D\\mid\\theta) = \\prod_{i=1}^N P(x_i,y_i\\mid\\theta)\n",
    "$$\n",
    "\n",
    "which is a function of the model parameters and the data. From now on, we will refer to the likelihood function as $\\mathcal{L}$:\n",
    "\n",
    "$$ \\mathcal{L} \\equiv  P(D\\mid\\theta). $$\n",
    "\n",
    "For convenience (and also for numerical accuracy) this is often expressed in terms of the *log-likelihood*, which for our simple example is:\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L} = \\log P(D\\mid\\theta) = -\\frac{1}{2}\\sum_{i=1}^N\\left(\\log(2\\pi\\varepsilon_i^2) + \\frac{\\left[y_i - y_M(x_i;\\theta)\\right]^2}{\\varepsilon_i^2}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Write a python method that creates some Mock data with errors bars, given a known line (i.e. known slope and intercept). We will fit this data below in order to recover the line parameters.\n",
    "\n",
    "2. Write a Python function which computes the log-likelihood given a parameter vector $\\theta$, an array of errors $\\varepsilon$, and an array of $x$ and $y$ values\n",
    "\n",
    "3. Use tools in [`scipy.optimize`](http://docs.scipy.org/doc/scipy/reference/optimize.html) to maximize this likelihood (i.e. minimize the negative log-likelihood). How close is this result to the input ``theta_true`` that you provided in exercise 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful references\n",
    "\n",
    "- Bevington, Data reduction and analysis for the physical sciences\n",
    "- Lyons, Statistics for nuclear and particle physicists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The case of *Fermi* LAT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the input model is the distribution of gamma-ray sources on the sky and includes their intensity and spectra. One will maximize $\\mathcal{L}$ to get the best match of the model to the data. Given a set of data, one can bin them in multidimensional (energy, sky pixels, time etc) bins.\n",
    "\n",
    "The observed number of counts in a bin $i$ is characterized by the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution). $\\mathcal{L}$ is the product of the probabilities of observing the detected counts in each bin, $n_i$, while $m_i$ counts are predicted by the model:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\prod_i \\mathcal{L}_i = \\prod_i \\frac{m_i^{n_i} e^{-m_i}}{n_i !}\n",
    "$$\n",
    "\n",
    "Using the properties of the product, $\\mathcal{L}$ can be written in a slightly more convenient way:\n",
    "\n",
    "$$\\mathcal{L} = \\prod_i e^{-m_i} \\prod_i \\frac{m_i^{n_i}}{n_i !} = e^{-N_{\\rm pred}} \\prod_i \\frac{m_i^{n_i}}{n_i !}  $$\n",
    "\n",
    "where $N_{\\rm pred}$ is the predicted total number of counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE for Fermi \n",
    "writing the likelihood function\n",
    "follow Julie’s notes\n",
    "\n",
    "How to do it in practice: tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Solutions to exercises](fermi_likelihood_lecture-solutions.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
